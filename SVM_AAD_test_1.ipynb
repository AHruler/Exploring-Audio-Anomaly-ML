{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_35340\\3009140598.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_json\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'working/audio_features.json'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m df_nested_list = pd.json_normalize(df, record_path =['features'],\n\u001B[0m\u001B[0;32m      9\u001B[0m                                    errors='ignore')\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_normalize.py\u001B[0m in \u001B[0;36m_json_normalize\u001B[1;34m(data, record_path, meta, meta_prefix, record_prefix, errors, sep, max_level)\u001B[0m\n\u001B[0;32m    513\u001B[0m                 \u001B[0mrecords\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    514\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 515\u001B[1;33m     \u001B[0m_recursive_extract\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecord_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    516\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    517\u001B[0m     \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_normalize.py\u001B[0m in \u001B[0;36m_recursive_extract\u001B[1;34m(data, path, seen_meta, level)\u001B[0m\n\u001B[0;32m    495\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    496\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mobj\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 497\u001B[1;33m                 \u001B[0mrecs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_pull_records\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    498\u001B[0m                 recs = [\n\u001B[0;32m    499\u001B[0m                     \u001B[0mnested_to_record\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msep\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msep\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_level\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmax_level\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_normalize.py\u001B[0m in \u001B[0;36m_pull_records\u001B[1;34m(js, spec)\u001B[0m\n\u001B[0;32m    417\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mhas\u001B[0m \u001B[0mnon\u001B[0m \u001B[0miterable\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    418\u001B[0m         \"\"\"\n\u001B[1;32m--> 419\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_pull_field\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mspec\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mextract_record\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    420\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    421\u001B[0m         \u001B[1;31m# GH 31507 GH 30145, GH 26284 if result is not list, raise TypeError if not\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_normalize.py\u001B[0m in \u001B[0;36m_pull_field\u001B[1;34m(js, spec, extract_record)\u001B[0m\n\u001B[0;32m    394\u001B[0m                     \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mfield\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    395\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 396\u001B[1;33m                 \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mspec\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    397\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    398\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mextract_record\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.datasets import make_blobs\n",
    "from numpy import quantile, where, random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('working/audio_features.json')\n",
    "df_nested_list = pd.json_normalize(df, record_path =['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<bound method Series.isna of fan/id_00\\abnormal\\00000000.wav    {'features': [-23.14673425319661, 2.9508236964...\nfan/id_00\\abnormal\\00000001.wav    {'features': [-23.075589556815537, 2.814327686...\nfan/id_00\\abnormal\\00000002.wav    {'features': [-23.73934065025545, 2.9942088625...\nfan/id_00\\abnormal\\00000003.wav    {'features': [-22.748752785911215, 2.787962125...\nfan/id_00\\abnormal\\00000004.wav    {'features': [-22.924125789369917, 2.746891582...\n                                                         ...                        \nfan/id_00\\normal\\00001006.wav                                                    NaN\nfan/id_00\\normal\\00001007.wav                                                    NaN\nfan/id_00\\normal\\00001008.wav                                                    NaN\nfan/id_00\\normal\\00001009.wav                                                    NaN\nfan/id_00\\normal\\00001010.wav                                                    NaN\nName: abnormal, Length: 1418, dtype: object>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_nested_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_35340\\4196237798.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdf_nested_list\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'df_nested_list' is not defined"
     ]
    }
   ],
   "source": [
    "df_nested_list.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_test(train_size,device='fan',id=0):\n",
    "\n",
    "    # function to label + split audio data\n",
    "\n",
    "    dir,label = audiodir(device,id)\n",
    "    dir_abnormal,label_abnormal = audiodir(device,id,Data='abnormal')\n",
    "\n",
    "    dataset_normal = MIMII(dir,label)\n",
    "    dataset_abnormal = MIMII(dir_abnormal,label_abnormal)\n",
    "    train_dataset, test_normal_dataset = torch.utils.data.random_split(dataset_normal, [int(len(dataset_normal)*train_size), len(dataset_normal)- int(len(dataset_normal)*train_size)])\n",
    "\n",
    "    test_dataset = ConcatDataset([test_normal_dataset, dataset_abnormal])\n",
    "\n",
    "    Train = torch.utils.data.DataLoader(train_dataset, shuffle=True,num_workers=4,drop_last=True)\n",
    "    Test = torch.utils.data.DataLoader(test_dataset, shuffle=True,num_workers=4)\n",
    "    return Train,Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_35340\\2423953469.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mTrain\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mTest\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_test\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.75\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'fan'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'train_test' is not defined"
     ]
    }
   ],
   "source": [
    "Train,Test = train_test(0.75,device='fan',id=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def MelSpec(y, sr):\n",
    "    S = torchaudio.transforms.MelSpectrogram(sample_rate=sr, n_fft=2048, hop_length=512, f_max=sr / 2, norm='slaney',\n",
    "                                             mel_scale='slaney')(y)\n",
    "    S_dB = torchaudio.transforms.AmplitudeToDB()(S)\n",
    "    return S_dB\n",
    "\n",
    "\n",
    "def mfcc_extract(filename):\n",
    "    try:\n",
    "        y, sr = librosa.load(filename, sr=44100)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, n_fft=int(0.02 * sr), hop_length=int(0.01 * sr))\n",
    "        return mfcc\n",
    "    except:\n",
    "        return"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
