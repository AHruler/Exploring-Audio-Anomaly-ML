{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyAudioProcessing.extract_features import get_features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        \n",
      " Extracting features gfcc, mfcc \n",
      "\n",
      "        \n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\n{\\n  music: {file1_path: {\"features\": <list>, \"feature_names\": <list>}, ...},\\n  speech: {file1_path: {\"features\": <list>, \"feature_names\": <list>}, ...},\\n  ...\\n}\\n'"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or if you have a dir with  sub-folders and audios\n",
    "features = get_features(folder_path=\"fan/id_00\", feature_names=[\"gfcc\", \"mfcc\"])\n",
    "\n",
    "# features is a dictionary that will hold data of the following format\n",
    "\"\"\"\n",
    "{\n",
    "  music: {file1_path: {\"features\": <list>, \"feature_names\": <list>}, ...},\n",
    "  speech: {file1_path: {\"features\": <list>, \"feature_names\": <list>}, ...},\n",
    "  ...\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'features' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved in audio_features.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyAudioProcessing import utils\n",
    "utils.write_to_json(\"audio_features.json\", features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'fan/id_00/normal/00000400.wav'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_43492\\2367295736.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mpyAudioProcessing\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mplot\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m plot.spectrogram('fan/id_00/normal/00000400.wav',\n\u001B[0m\u001B[0;32m      4\u001B[0m     \u001B[0mshow\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     )\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyAudioProcessing\\plot.py\u001B[0m in \u001B[0;36mspectrogram\u001B[1;34m(input_file, show, save_to_disk, output_file)\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[0mPlot\u001B[0m \u001B[0mspctrogram\u001B[0m \u001B[0mof\u001B[0m \u001B[0minput\u001B[0m \u001B[0maudio\u001B[0m \u001B[0msignal\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0msave\u001B[0m \u001B[0mthe\u001B[0m \u001B[0moutput\u001B[0m \u001B[0mto\u001B[0m \u001B[0mdisk\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m     \"\"\"\n\u001B[1;32m---> 22\u001B[1;33m     \u001B[0msampling_rate\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msignal\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mread_audio\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m     \u001B[1;31m# Prepare the signal for spectrogram computation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msignal\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyAudioProcessing\\utils.py\u001B[0m in \u001B[0;36mread_audio\u001B[1;34m(input_file)\u001B[0m\n\u001B[0;32m     66\u001B[0m         \u001B[0mextension\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplitext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mextension\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\".wav\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 68\u001B[1;33m             \u001B[0msampling_rate\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msignal\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mwavfile\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     69\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     70\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\io\\wavfile.py\u001B[0m in \u001B[0;36mread\u001B[1;34m(filename, mmap)\u001B[0m\n\u001B[0;32m    542\u001B[0m         \u001B[0mmmap\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    543\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 544\u001B[1;33m         \u001B[0mfid\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'rb'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    545\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    546\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'fan/id_00/normal/00000400.wav'"
     ]
    }
   ],
   "source": [
    "from pyAudioProcessing import plot\n",
    "\n",
    "plot.spectrogram('fan/id_00/normal/00000400.wav',\n",
    "    show=True,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot.spectrogram('fan/id_00/abnormal/00000001.wav',\n",
    "                 show=True,\n",
    "                 )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load paths and labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pydub\n",
    "\n",
    "\n",
    "def load_data(machine, Data = 'normal', base_dir = 'data/', id = [0, 2, 4, 6]):\n",
    "    '''\n",
    "     Find the audio directory\n",
    "     Inputs:\n",
    "     machine: Name of the machine (valve/slider/fan/pump)\n",
    "     id: ID of the machine (0,2,4,6)\n",
    "     base_dir = Base directory of the dataset\n",
    "\n",
    "     Outputs:\n",
    "     dir = List of data adresses\n",
    "     label = List of labels (0 -> normal, 1 -> abnormal)\n",
    "     '''\n",
    "\n",
    "\n",
    "    dir = []\n",
    "    label = []\n",
    "\n",
    "    for id in id:\n",
    "        normaldir = base_dir + machine + '/id_' + str(format(id,'02d')) + '/normal'\n",
    "        abnormaldir = base_dir + machine + '/id_' + str(format(id,'02d')) + '/abnormal'\n",
    "        if Data == 'normal':\n",
    "            list = os.listdir(normaldir)\n",
    "            for i in list:\n",
    "                dir_address = normaldir + '/' + i\n",
    "                dir.append(dir_address)\n",
    "                label.append(0)\n",
    "\n",
    "        else:\n",
    "            list = os.listdir(abnormaldir)\n",
    "            for i in list:\n",
    "                dir_address = abnormaldir + '/' + i\n",
    "                dir.append(dir_address)\n",
    "                label.append(1)\n",
    "\n",
    "    return dir,label\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "device='fan'\n",
    "dir,label = load_data(device)\n",
    "\n",
    "dir_abnormal,label_abnormal = load_data(device, Data='abnormal')\n",
    "\n",
    "\n",
    "f1 = {'filename': (dir_abnormal + dir), 'label': (label_abnormal + label)}\n",
    "df = pd.DataFrame(f1)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define feature extraction functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "# def mfcc_extract(filename):\n",
    "#\n",
    "#     y, sr  = librosa.load(filename, sr = 16000)\n",
    "#     mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, n_fft=2048, hop_length=512)\n",
    "#     return mfcc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mfcc and Lfcc using Torch audio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "n_fft = 1024\n",
    "win_length = None\n",
    "hop_length = 512\n",
    "n_mels = 128\n",
    "n_mfcc = 13\n",
    "input_freq=16000\n",
    "\n",
    "def mfcc_extract(filename):\n",
    "\n",
    "    y, _ = torchaudio.load(filename, normalize=True)\n",
    "    transform = transforms.MFCC(sample_rate = input_freq, n_mfcc=n_mfcc,\n",
    "        melkwargs={\n",
    "            \"n_fft\": n_fft,\n",
    "            \"n_mels\": n_mels,\n",
    "            \"win_length\": win_length,\n",
    "            \"hop_length\": hop_length,\n",
    "        },)\n",
    "    mfcc = transform(y).numpy()\n",
    "    stddev_mfccs = np.std(mfcc, axis=1)\n",
    "\n",
    "    mean_mfccs = np.mean(mfcc, axis=1)\n",
    "\n",
    "    average_difference = np.zeros(((len(mfcc),))\n",
    "    for i in range(0, len(mfcc.T) - 2, 2):\n",
    "        average_difference += mfcc.T[i] - mfcc.T[i+1]\n",
    "\n",
    "    average_difference /= (len(mfcc) // 2)\n",
    "    m_difference = np.array(average_difference)\n",
    "\n",
    "    return mfcc, stddev_mfccs, mean_mfccs, m_difference\n",
    "\n",
    "\n",
    "n_lfcc = 13\n",
    "\n",
    "def lfcc_extract(filename):\n",
    "    y, _ = torchaudio.load(filename, normalize=True)\n",
    "    transform = transforms.LFCC(\n",
    "        sample_rate=input_freq,\n",
    "        n_lfcc=n_lfcc,\n",
    "        speckwargs={\n",
    "            \"n_fft\": n_fft,\n",
    "            \"win_length\": win_length,\n",
    "            \"hop_length\": hop_length,\n",
    "        },\n",
    "    )\n",
    "    lfcc = transform(y)\n",
    "    return lfcc.numpy()\n",
    "\n",
    "## plotting function\n",
    "def plot_spectrogram(specgram, title=None, ylabel=\"freq_bin\"):\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    axs.set_title(title or \"Spectrogram (db)\")\n",
    "    axs.set_ylabel(ylabel)\n",
    "    axs.set_xlabel(\"frame\")\n",
    "    im = axs.imshow(librosa.power_to_db(specgram), origin=\"lower\", aspect=\"auto\")\n",
    "    fig.colorbar(im, ax=axs)\n",
    "    plt.show(block=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test on sample path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mfcc_test, stddev_mfccs, mean_mfccs, average_difference = mfcc_extract(df.filename[1])\n",
    "mfcc_test_normal = mfcc_extract(df.filename[1476])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_spectrogram(mfcc_test[7])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_spectrogram(mfcc_test_normal[7])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Apply to full list of paths for clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_43492\\1992762119.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mmfcc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'filename'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mmfcc_extract\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mlfcc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'filename'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mlfcc_extract\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[0;32m   4431\u001B[0m         \u001B[0mdtype\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mfloat64\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4432\u001B[0m         \"\"\"\n\u001B[1;32m-> 4433\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mSeriesApply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconvert_dtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   4434\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4435\u001B[0m     def _reduce(\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1086\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_str\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1087\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1088\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_standard\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1089\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1090\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0magg\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001B[0m in \u001B[0;36mapply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1141\u001B[0m                 \u001B[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1142\u001B[0m                 \u001B[1;31m# \"Callable[[Any], Any]\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1143\u001B[1;33m                 mapped = lib.map_infer(\n\u001B[0m\u001B[0;32m   1144\u001B[0m                     \u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1145\u001B[0m                     \u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[1;31m# type: ignore[arg-type]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001B[0m in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_43492\\1992762119.py\u001B[0m in \u001B[0;36m<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mmfcc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'filename'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mmfcc_extract\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mlfcc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'filename'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mlfcc_extract\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_43492\\3224458229.py\u001B[0m in \u001B[0;36mmfcc_extract\u001B[1;34m(filename)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mmfcc_extract\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m     \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorchaudio\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnormalize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m     transform = transforms.MFCC(sample_rate = input_freq, n_mfcc=n_mfcc,\n\u001B[0;32m     12\u001B[0m         melkwargs={\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\torchaudio\\backend\\soundfile_backend.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001B[0m\n\u001B[0;32m    203\u001B[0m             \u001B[0;31m`\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mchannel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m]\u001B[0m\u001B[0;31m`\u001B[0m \u001B[1;32melse\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mchannel\u001B[0m\u001B[1;33m]\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    204\u001B[0m     \"\"\"\n\u001B[1;32m--> 205\u001B[1;33m     \u001B[1;32mwith\u001B[0m \u001B[0msoundfile\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSoundFile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"r\"\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mfile_\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    206\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mfile_\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;34m\"WAV\"\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mnormalize\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m             \u001B[0mdtype\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"float32\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\soundfile.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001B[0m\n\u001B[0;32m    653\u001B[0m         self._info = _create_info_struct(file, mode, samplerate, channels,\n\u001B[0;32m    654\u001B[0m                                          format, subtype, endian)\n\u001B[1;32m--> 655\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_file\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_open\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode_int\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclosefd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    656\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0missuperset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'r+'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mseekable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    657\u001B[0m             \u001B[1;31m# Move write position to 0 (like in Python file objects)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Anaconda3\\lib\\site-packages\\soundfile.py\u001B[0m in \u001B[0;36m_open\u001B[1;34m(self, file, mode_int, closefd)\u001B[0m\n\u001B[0;32m   1200\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1201\u001B[0m                     \u001B[0mfile\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfile\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_sys\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgetfilesystemencoding\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1202\u001B[1;33m             \u001B[0mfile_ptr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mopenfunction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode_int\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_info\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1203\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1204\u001B[0m             \u001B[0mfile_ptr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_snd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msf_open_fd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode_int\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_info\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclosefd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "mfcc = df['filename'].apply(lambda x: mfcc_extract(x))\n",
    "lfcc = df['filename'].apply(lambda x: lfcc_extract(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(mfcc[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(mfcc[1][1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pitch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchaudio.functional as F\n",
    "import torch\n",
    "\n",
    "def wave_sr_extract(filename):\n",
    "    y, sr = torchaudio.load(filename, normalize=True)\n",
    "    return y, sr\n",
    "\n",
    "def pitch_extract(w,sr):\n",
    "    pitch = F.detect_pitch_frequency(w, sr)\n",
    "    return pitch\n",
    "\n",
    "def df_pitch_extract(filename):\n",
    "    w, sr = torchaudio.load(filename, normalize=True)\n",
    "    pitch = F.detect_pitch_frequency(w, sr)\n",
    "    return pitch\n",
    "\n",
    "\n",
    "def plot_pitch(waveform, sr, pitch):\n",
    "    figure, axis = plt.subplots(1, 1)\n",
    "    axis.set_title(\"Pitch Feature\")\n",
    "    axis.grid(True)\n",
    "\n",
    "    end_time = waveform.shape[1] / sr\n",
    "    time_axis = torch.linspace(0, end_time, waveform.shape[1])\n",
    "    axis.plot(time_axis, waveform[0], linewidth=1, color=\"gray\", alpha=0.3)\n",
    "\n",
    "    axis2 = axis.twinx()\n",
    "    time_axis = torch.linspace(0, end_time, pitch.shape[1])\n",
    "    axis2.plot(time_axis, pitch[0], linewidth=2, label=\"Pitch\", color=\"green\")\n",
    "\n",
    "    axis2.legend(loc=0)\n",
    "    plt.show(block=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w1, sr1 = wave_sr_extract(df.filename[2])\n",
    "w2, sr2 = wave_sr_extract(df.filename[1481])\n",
    "pitch1 = pitch_extract(w1,sr1)\n",
    "pitch2 = pitch_extract(w2,sr2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_pitch(w1, sr1, pitch1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_pitch(w2, sr2, pitch2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pitch = df['filename'].apply(lambda x: df_pitch_extract(x))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pitch.numpy()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get mean and sd of fcc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f = len(mfcc)\n",
    "t = 8 # 8 ?\n",
    "mel_n =13\n",
    "#save in vectors\n",
    "stddev_mfcc = []\n",
    "stddev_lfcc = []\n",
    "mean_mfcc = []\n",
    "mean_lfcc = []\n",
    "for k in range(f):\n",
    "    for j in range(t):\n",
    "        # Get the standard deviation\n",
    "        stddev_mfcc.append(np.std(mfcc[k][j], axis=0))\n",
    "        stddev_lfcc.append(np.std(lfcc[k][j], axis=0))\n",
    "\n",
    "        # Get the mean\n",
    "        mean_mfcc.append(np.mean(mfcc[k][j], axis=0))\n",
    "        mean_lfcc.append(np.mean(lfcc[k][j], axis=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mfcc_features = np.hstack((stddev_mfcc, mean_mfcc))\n",
    "\n",
    "lfcc_features = np.hstack((stddev_lfcc, mean_lfcc))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def get_scaled_umap_embeddings(features, neighbour, distance):\n",
    "\n",
    "    embedding = umap.UMAP(n_neighbors=neighbour,\n",
    "                          min_dist=distance,\n",
    "                          metric='correlation').fit_transform(features)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(embedding)\n",
    "    return scaler.transform(embedding)\n",
    "\n",
    "\n",
    "umap_embeddings_mfccs = []\n",
    "umap_embeddings_wavenet = []\n",
    "neighbours = [5, 10, 15, 30, 50]\n",
    "distances = [0.000, 0.001, 0.01, 0.1, 0.5]\n",
    "\n",
    "for neighbour in neighbours:\n",
    "    for distance in distances:\n",
    "        umap_mfccs = get_scaled_umap_embeddings(mfcc_features,\n",
    "                                                neighbour,\n",
    "                                                distance)\n",
    "        umap_lfccs = get_scaled_umap_embeddings(lfcc_features,\n",
    "                                                  neighbour,\n",
    "                                                  distance)\n",
    "        umap_embeddings_mfccs.append(umap_mfccs)\n",
    "    umap_embeddings_wavenet.append(umap_wavenet)\n",
    "\n",
    "    mfcc_key = 'umapmfcc{}{}'.format(i, j)\n",
    "    wavenet_key = 'umapwavenet{}{}'.format(i, j)#%%\n",
    "import pandas as pd\n",
    "from pyAudioProcessing.extract_features import get_features\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# or if you have a dir with  sub-folders and audios\n",
    "features = get_features(folder_path=\"fan/id_00\", feature_names=[\"gfcc\", \"mfcc\"])\n",
    "\n",
    "# features is a dictionary that will hold data of the following format\n",
    "\"\"\"\n",
    "{\n",
    "  music: {file1_path: {\"features\": <list>, \"feature_names\": <list>}, ...},\n",
    "  speech: {file1_path: {\"features\": <list>, \"feature_names\": <list>}, ...},\n",
    "  ...\n",
    "}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%store features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyAudioProcessing import utils\n",
    "utils.write_to_json(\"audio_features.json\", features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyAudioProcessing import plot\n",
    "\n",
    "plot.spectrogram('fan/id_00/normal/00000400.wav',\n",
    "    show=True,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot.spectrogram('fan/id_00/abnormal/00000001.wav',\n",
    "                 show=True,\n",
    "                 )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load paths and labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pydub\n",
    "\n",
    "\n",
    "def load_data(machine, Data = 'normal', base_dir = 'data/', id = [0, 2, 4, 6]):\n",
    "    '''\n",
    "     Find the audio directory\n",
    "     Inputs:\n",
    "     machine: Name of the machine (valve/slider/fan/pump)\n",
    "     id: ID of the machine (0,2,4,6)\n",
    "     base_dir = Base directory of the dataset\n",
    "\n",
    "     Outputs:\n",
    "     dir = List of data adresses\n",
    "     label = List of labels (0 -> normal, 1 -> abnormal)\n",
    "     '''\n",
    "\n",
    "\n",
    "    dir = []\n",
    "    label = []\n",
    "\n",
    "    for id in id:\n",
    "        normaldir = base_dir + machine + '/id_' + str(format(id,'02d')) + '/normal'\n",
    "        abnormaldir = base_dir + machine + '/id_' + str(format(id,'02d')) + '/abnormal'\n",
    "        if Data == 'normal':\n",
    "            list = os.listdir(normaldir)\n",
    "            for i in list:\n",
    "                dir_address = normaldir + '/' + i\n",
    "                dir.append(dir_address)\n",
    "                label.append(0)\n",
    "\n",
    "        else:\n",
    "            list = os.listdir(abnormaldir)\n",
    "            for i in list:\n",
    "                dir_address = abnormaldir + '/' + i\n",
    "                dir.append(dir_address)\n",
    "                label.append(1)\n",
    "\n",
    "    return dir,label\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "device='fan'\n",
    "dir,label = load_data(device)\n",
    "\n",
    "dir_abnormal,label_abnormal = load_data(device, Data='abnormal')\n",
    "\n",
    "\n",
    "f1 = {'filename': (dir_abnormal + dir), 'label': (label_abnormal + label)}\n",
    "df = pd.DataFrame(f1)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define feature extraction functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sb\n",
    "sb.set(style=\"white\", palette=\"muted\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "# def mfcc_extract(filename):\n",
    "#\n",
    "#     y, sr  = librosa.load(filename, sr = 16000)\n",
    "#     mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, n_fft=2048, hop_length=512)\n",
    "#     return mfcc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mfcc and Lfcc using Torch audio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "n_fft = 1024\n",
    "win_length = None\n",
    "hop_length = 512\n",
    "n_mels = 128\n",
    "n_mfcc = 13\n",
    "input_freq=16000\n",
    "\n",
    "def mfcc_extract(filename):\n",
    "\n",
    "    y, _ = torchaudio.load(filename, normalize=True)\n",
    "    transform = transforms.MFCC(sample_rate = input_freq, n_mfcc=n_mfcc,\n",
    "        melkwargs={\n",
    "            \"n_fft\": n_fft,\n",
    "            \"n_mels\": n_mels,\n",
    "            \"win_length\": win_length,\n",
    "            \"hop_length\": hop_length,\n",
    "        },)\n",
    "    mfcc = transform(y).numpy()\n",
    "    return mfcc\n",
    "\n",
    "\n",
    "n_lfcc = 13\n",
    "\n",
    "def lfcc_extract(filename):\n",
    "    y, _ = torchaudio.load(filename, normalize=True)\n",
    "    transform = transforms.LFCC(\n",
    "        sample_rate=input_freq,\n",
    "        n_lfcc=n_lfcc,\n",
    "        speckwargs={\n",
    "            \"n_fft\": n_fft,\n",
    "            \"win_length\": win_length,\n",
    "            \"hop_length\": hop_length,\n",
    "        },\n",
    "    )\n",
    "    lfcc = transform(y)\n",
    "    return lfcc.numpy()\n",
    "\n",
    "## plotting function\n",
    "def plot_spectrogram(specgram, title=None, ylabel=\"freq_bin\"):\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    axs.set_title(title or \"Spectrogram (db)\")\n",
    "    axs.set_ylabel(ylabel)\n",
    "    axs.set_xlabel(\"frame\")\n",
    "    im = axs.imshow(librosa.power_to_db(specgram), origin=\"lower\", aspect=\"auto\")\n",
    "    fig.colorbar(im, ax=axs)\n",
    "    plt.show(block=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test on sample path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mfcc_test, stddev_mfccs, mean_mfccs, average_difference = mfcc_extract(df.filename[1])\n",
    "mfcc_test_normal = mfcc_extract(df.filename[1476])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_spectrogram(mfcc_test[7])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_spectrogram(mfcc_test_normal[7])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Apply to full list of paths for clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mfcc = df['filename'].apply(lambda x: mfcc_extract(x))\n",
    "lfcc = df['filename'].apply(lambda x: lfcc_extract(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(mfcc[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(mfcc[1][1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pitch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchaudio.functional as F\n",
    "import torch\n",
    "\n",
    "def wave_sr_extract(filename):\n",
    "    y, sr = torchaudio.load(filename, normalize=True)\n",
    "    return y, sr\n",
    "\n",
    "def pitch_extract(w,sr):\n",
    "    pitch = F.detect_pitch_frequency(w, sr)\n",
    "    return pitch\n",
    "\n",
    "def df_pitch_extract(filename):\n",
    "    w, sr = torchaudio.load(filename, normalize=True)\n",
    "    pitch = F.detect_pitch_frequency(w, sr)\n",
    "    return pitch\n",
    "\n",
    "\n",
    "def plot_pitch(waveform, sr, pitch):\n",
    "    figure, axis = plt.subplots(1, 1)\n",
    "    axis.set_title(\"Pitch Feature\")\n",
    "    axis.grid(True)\n",
    "\n",
    "    end_time = waveform.shape[1] / sr\n",
    "    time_axis = torch.linspace(0, end_time, waveform.shape[1])\n",
    "    axis.plot(time_axis, waveform[0], linewidth=1, color=\"gray\", alpha=0.3)\n",
    "\n",
    "    axis2 = axis.twinx()\n",
    "    time_axis = torch.linspace(0, end_time, pitch.shape[1])\n",
    "    axis2.plot(time_axis, pitch[0], linewidth=2, label=\"Pitch\", color=\"green\")\n",
    "\n",
    "    axis2.legend(loc=0)\n",
    "    plt.show(block=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "w1, sr1 = wave_sr_extract(df.filename[2])\n",
    "w2, sr2 = wave_sr_extract(df.filename[1481])\n",
    "pitch1 = pitch_extract(w1,sr1)\n",
    "pitch2 = pitch_extract(w2,sr2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_pitch(w1, sr1, pitch1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_pitch(w2, sr2, pitch2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pitch = df['filename'].apply(lambda x: df_pitch_extract(x))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pitch.numpy()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get mean and sd of fcc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "f = len(mfcc)\n",
    "t = 8 # 8 ?\n",
    "mel_n =13\n",
    "#save in vectors\n",
    "stddev_mfcc = []\n",
    "stddev_lfcc = []\n",
    "sd1 = []\n",
    "sd2 = []\n",
    "\n",
    "mean_mfcc = []\n",
    "mean_lfcc = []\n",
    "mean1 = []\n",
    "mean2 = []\n",
    "for k in range(f):\n",
    "    for j in range(t):\n",
    "        # Get the standard deviation\n",
    "        sd1.append(np.std(mfcc[k][j], axis=0))\n",
    "        sd2.append(np.std(lfcc[k][j], axis=0))\n",
    "\n",
    "        # Get the mean\n",
    "        mean1.append(np.mean(mfcc[k][j], axis=0))\n",
    "        mean2.append(np.mean(lfcc[k][j], axis=0))\n",
    "\n",
    "    mean_mfcc.append(np.mean(mean1, axis=0))\n",
    "    mean_lfcc.append(np.mean(mean2, axis=0))\n",
    "\n",
    "    stddev_mfcc.append(np.mean(sd1, axis=0))\n",
    "    stddev_lfcc.append(np.mean(sd2, axis=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_51164\\1611434450.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mmfccs_features\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhstack\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstddev_mfcc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmean_mfcc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mlfcc_features\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhstack\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstddev_lfcc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmean_lfcc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "mfccs_features = np.hstack((stddev_mfcc, mean_mfcc))\n",
    "lfcc_features = np.hstack((stddev_lfcc, mean_lfcc))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def get_scaled_umap_embeddings(features, neighbour, distance):\n",
    "\n",
    "    embedding = umap.UMAP(n_neighbors=neighbour,\n",
    "                          min_dist=distance,\n",
    "                          metric='correlation').fit_transform(features)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(embedding)\n",
    "    return scaler.transform(embedding)\n",
    "\n",
    "\n",
    "umap_embeddings_mfccs = []\n",
    "umap_embeddings_lfccs = []\n",
    "neighbours = [5, 10, 15, 30, 50]\n",
    "distances = [0.000, 0.001, 0.01, 0.1, 0.5]\n",
    "\n",
    "for neighbour in neighbours:\n",
    "    for distance in distances:\n",
    "        umap_mfccs = get_scaled_umap_embeddings(mfcc_features,\n",
    "                                                neighbour,\n",
    "                                                distance)\n",
    "        umap_lfccs = get_scaled_umap_embeddings(lfcc_features,\n",
    "                                                  neighbour,\n",
    "                                                  distance)\n",
    "        umap_embeddings_mfccs.append(umap_mfccs)\n",
    "        umap_embeddings_lfccs.append(umap_lfccs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'neighbours' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_51164\\2751606900.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0msb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstyle\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"white\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpalette\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"muted\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m fig, ax = plt.subplots(nrows=len(neighbours),\n\u001B[0m\u001B[0;32m      9\u001B[0m                        \u001B[0mncols\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdistances\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m                        figsize=(30, 30))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'neighbours' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sb\n",
    "sb.set(style=\"white\", palette=\"muted\")\n",
    "\n",
    "fig, ax = plt.subplots(nrows=len(neighbours),\n",
    "                       ncols=len(distances),\n",
    "                       figsize=(30, 30))\n",
    "\n",
    "for i, row in enumerate(ax):\n",
    "    for j, col in enumerate(row):\n",
    "        current_plot = i * len(iterations) + j\n",
    "        col.scatter(umap_embeddings_mfccs[current_plot].T[0],\n",
    "                    umap_embeddings_mfccs[current_plot].T[1],\n",
    "                    s=1)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_51164\\324483818.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmfcc_features\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(mfcc_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#PCA for reducing dimensions to 3\n",
    "pca = PCA(n_components=3)\n",
    "pca_X = pca.fit_transform(X)\n",
    "\n",
    "\n",
    "colors = np.array([x for x in 'bgrcmykbgr'])\n",
    "#running k-means on resuts of pca\n",
    "km_pca = KMeans(n_clusters=4).fit(pca_X)\n",
    "fig = px.scatter_3d(x=pca_X[:,0], y=pca_X[:,1], z=pca_X[:,2],color=colors[km_pca.labels_])\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_f = pd.DataFrame("
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
